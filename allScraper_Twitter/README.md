Please see below:

This is a flowchart of how the project was done:

<img src="https://github.com/keshariS/dataScrapers/blob/main/allScraper_Twitter/tw.png" width="240">

The use of every python file/python notebook is mentioned in the first line as a comment.

Folders:
classifier: contains data used by Prof. Dobbs in their paper. Can be used to replicate results (not completed yet, but the paper pdf is included)
data_16k_tweets: contains the first iteration done in twitter scraping before the spritzer stream for the VAMoS project (we had scraped 16k tweets for the hashtags)
misc_codes: contains python files for scraping data using the twarc 2 API
spritzer2categories: contains code for querying the 465M spritzer stream data aand convert into categories as needed for the VAMoS project
topicModels: contains the topic modeling results per iteration

